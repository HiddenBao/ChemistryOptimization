{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f38d2a-db7a-4fd8-9a80-257d42b641d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Importing all needed libraries\n",
    "try:\n",
    "    # Summit-related imports\n",
    "    import summit\n",
    "    from summit.benchmarks import ExperimentalEmulator\n",
    "    from summit.domain import *\n",
    "    from summit.utils.dataset import DataSet\n",
    "    from summit.strategies import SOBO, MultitoSingleObjective, LHS\n",
    "\n",
    "    # External libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # File and path handling\n",
    "    import pathlib\n",
    "    import os\n",
    "    import logging\n",
    "    import re\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please install the required libraries before running the program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c245d1b0-5209-4b52-a0dc-7a38c748a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurable parameters\n",
    "base_path = pathlib.Path(\"D:/!PythonCode/ChemistryOptimization/DataSets/MidazTest\")\n",
    "PROJECT_NAME = \"MidazTest\"\n",
    "BOUNDS_NAME = f\"{PROJECT_NAME}_Bounds.csv\"\n",
    "DATA_NAME = f\"{PROJECT_NAME}_Data.csv\"\n",
    "LOG_NAME = f\"{PROJECT_NAME}_Log.csv\"\n",
    "#BOUNDS_NAME = \"Nakul_Midazolam_BoundariesV2.csv\"\n",
    "#DATA_NAME = \"StartExp.csv\"\n",
    "\n",
    "# Folder Name\n",
    "DATA_DIR = \"Data\"\n",
    "MODEL_DIR = \"Models\"\n",
    "IT_DIR = \"IterData\"\n",
    "LOG_DIR = \"Logs\"\n",
    "\n",
    "# Function to create directory if it doesn't exist\n",
    "def create_directory(base_path, directory):\n",
    "    \"\"\"Create a directory if it doesn't exist.\"\"\"\n",
    "    dir_path = base_path / directory\n",
    "    if not dir_path.is_dir():\n",
    "        dir_path.mkdir(parents=True)\n",
    "        \n",
    "# Create directories\n",
    "for directory in [DATA_DIR, MODEL_DIR, IT_DIR, LOG_DIR]:\n",
    "    create_directory(base_path, directory)\n",
    "\n",
    "# Set data paths\n",
    "data_path = base_path / DATA_DIR\n",
    "model_path = base_path / MODEL_DIR\n",
    "it_path = base_path / IT_DIR\n",
    "log_path = base_path / LOG_DIR\n",
    "\n",
    "# Configure logging\n",
    "log_file_path = log_path / LOG_NAME\n",
    "logging.basicConfig(\n",
    "    filename = log_file_path,\n",
    "    level = logging.INFO,\n",
    "    format = \"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Load initial boundaries data\n",
    "try:\n",
    "    init_bounds_df = pd.read_csv(data_path / BOUNDS_NAME)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{BOUNDS_NAME}' not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: File '{BOUNDS_NAME}' is empty or in an invalid format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c6031d-910b-4abd-ab45-1788c2fb936b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Type</th>\n",
       "      <th>Categories</th>\n",
       "      <th>BoundaryMin</th>\n",
       "      <th>BoundaryMax</th>\n",
       "      <th>Description</th>\n",
       "      <th>Maximize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Reaction temperature in degrees Celsius (ºC)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catalyst_Amount</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Catalyst amounts in molar equivalents (Equiv.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Starting_Reagent</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2-Methylimidozole amounts in molar equivalents...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solvent</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Solvent amount in milliliters (mL)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Duration of reaction in hours (hr)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Base</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Base amount in molar equivalents (Equiv.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Main_Product</td>\n",
       "      <td>Objective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LCAP of Main Product</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Main_Impurity</td>\n",
       "      <td>Objective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LCAP of Main Impurity</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Condition        Type  Categories  BoundaryMin  BoundaryMax  \\\n",
       "0       Temperature  Continuous         NaN        40.00        80.00   \n",
       "1   Catalyst_Amount  Continuous         NaN         0.01         1.00   \n",
       "2  Starting_Reagent  Continuous         NaN         1.10         2.00   \n",
       "3           Solvent  Continuous         NaN         0.10         0.35   \n",
       "4              Time  Continuous         NaN         2.00        24.00   \n",
       "5              Base  Continuous         NaN         1.00         5.00   \n",
       "6      Main_Product   Objective         NaN         0.00         1.00   \n",
       "7     Main_Impurity   Objective         NaN         0.00         1.00   \n",
       "\n",
       "                                         Description Maximize  \n",
       "0       Reaction temperature in degrees Celsius (ºC)      NaN  \n",
       "1     Catalyst amounts in molar equivalents (Equiv.)      NaN  \n",
       "2  2-Methylimidozole amounts in molar equivalents...      NaN  \n",
       "3                 Solvent amount in milliliters (mL)      NaN  \n",
       "4                 Duration of reaction in hours (hr)      NaN  \n",
       "5          Base amount in molar equivalents (Equiv.)      NaN  \n",
       "6                               LCAP of Main Product     True  \n",
       "7                              LCAP of Main Impurity    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_bounds_df #Temporary code to visualize the Boundaries.csv dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb47cec-fac8-41db-a60b-2bd1c7c34c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4.0', '\\n2024-01-05 12:03:36,737 - INFO - This is check step: 3\\n2024-01-05 12:03:36,961 - INFO - Expansion of bounds dataframe\\n2024-01-05 12:03:37,250 - INFO - initializing Y\\n2024-01-05 12:03:37,250 - INFO - initializing inference method\\n2024-01-05 12:03:37,250 - INFO - adding kernel and likelihood as parameters\\n2024-01-05 12:03:38,160 - INFO - '), ('4.0', '\\n2024-01-05 12:03:01,772 - INFO - This is check step: 3\\n2024-01-05 12:03:02,017 - INFO - Expansion of bounds dataframe\\n2024-01-05 12:03:02,575 - INFO - initializing Y\\n2024-01-05 12:03:02,576 - INFO - initializing inference method\\n2024-01-05 12:03:02,576 - INFO - adding kernel and likelihood as parameters\\n2024-01-05 12:03:03,474 - INFO - '), ('4.0', '\\n2024-01-04 14:54:54,822 - INFO - This is check step: 3\\n2024-01-04 14:54:55,029 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:54:55,318 - INFO - initializing Y\\n2024-01-04 14:54:55,318 - INFO - initializing inference method\\n2024-01-04 14:54:55,318 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:54:56,195 - INFO - '), ('4.0', '\\n2024-01-04 14:54:42,536 - INFO - This is check step: 3\\n2024-01-04 14:54:42,761 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:54:43,067 - INFO - initializing Y\\n2024-01-04 14:54:43,067 - INFO - initializing inference method\\n2024-01-04 14:54:43,067 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:54:43,979 - INFO - '), ('4.0', '\\n2024-01-04 14:54:26,107 - INFO - This is check step: 3\\n2024-01-04 14:54:26,333 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:54:26,605 - INFO - initializing Y\\n2024-01-04 14:54:26,605 - INFO - initializing inference method\\n2024-01-04 14:54:26,621 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:54:27,487 - INFO - '), ('4.0', '\\n2024-01-04 14:54:04,327 - INFO - This is check step: 3\\n2024-01-04 14:54:04,551 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:54:04,840 - INFO - initializing Y\\n2024-01-04 14:54:04,840 - INFO - initializing inference method\\n2024-01-04 14:54:04,840 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:54:05,730 - INFO - '), ('4.0', '\\n2024-01-04 14:53:50,527 - INFO - This is check step: 3\\n2024-01-04 14:53:50,741 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:53:51,011 - INFO - initializing Y\\n2024-01-04 14:53:51,011 - INFO - initializing inference method\\n2024-01-04 14:53:51,011 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:53:51,911 - INFO - '), ('4.0', '\\n2024-01-04 14:53:06,851 - INFO - This is check step: 3\\n2024-01-04 14:53:07,073 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:53:07,366 - INFO - initializing Y\\n2024-01-04 14:53:07,366 - INFO - initializing inference method\\n2024-01-04 14:53:07,366 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:53:08,231 - INFO - '), ('4.0', '\\n2024-01-04 14:48:21,105 - INFO - This is check step: 3\\n2024-01-04 14:48:21,339 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:48:21,652 - INFO - initializing Y\\n2024-01-04 14:48:21,652 - INFO - initializing inference method\\n2024-01-04 14:48:21,653 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:48:22,533 - INFO - '), ('4.0', '\\n2024-01-04 14:42:22,999 - INFO - This is check step: 4\\n2024-01-04 14:42:23,199 - WARNING - Optimization has been halted\\n2024-01-04 14:43:19,009 - INFO - Reading dataset: MidazTest_Data.csv\\n2024-01-04 14:43:19,009 - INFO - Iteration 4.0: Program started\\n2024-01-04 14:43:19,011 - INFO - This is check step: 3\\n2024-01-04 14:43:19,219 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:43:19,527 - INFO - initializing Y\\n2024-01-04 14:43:19,527 - INFO - initializing inference method\\n2024-01-04 14:43:19,527 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:43:20,424 - INFO - '), ('4.0', '\\n2024-01-04 14:41:35,792 - INFO - This is check step: 3\\n2024-01-04 14:41:36,002 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:41:36,288 - INFO - initializing Y\\n2024-01-04 14:41:36,288 - INFO - initializing inference method\\n2024-01-04 14:41:36,288 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:41:37,171 - INFO - '), ('4.0', '\\n2024-01-04 14:37:34,373 - INFO - This is check step: 3\\n2024-01-04 14:37:34,583 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:37:34,872 - INFO - initializing Y\\n2024-01-04 14:37:34,872 - INFO - initializing inference method\\n2024-01-04 14:37:34,888 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:37:35,750 - INFO - '), ('4.0', '\\n2024-01-04 14:20:25,931 - INFO - This is check step: 4\\n2024-01-04 14:20:26,130 - WARNING - Optimization has been halted\\n2024-01-04 14:22:45,838 - INFO - Reading dataset: MidazTest_Data.csv\\n2024-01-04 14:22:45,838 - INFO - Iteration 4.0: Program started\\n2024-01-04 14:22:45,858 - INFO - This is check step: 4\\n2024-01-04 14:22:46,048 - WARNING - Optimization has been halted\\n2024-01-04 14:22:59,563 - INFO - Reading dataset: MidazTest_Data.csv\\n2024-01-04 14:22:59,564 - INFO - Iteration 4.0: Program started\\n2024-01-04 14:22:59,571 - INFO - This is check step: 4\\n2024-01-04 14:22:59,765 - WARNING - Optimization has been halted\\n2024-01-04 14:28:20,943 - INFO - Reading dataset: MidazTest_Data.csv\\n2024-01-04 14:28:20,944 - INFO - Iteration 4.0: Program started\\n2024-01-04 14:28:20,947 - INFO - This is check step: 3\\n2024-01-04 14:28:21,189 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:28:21,645 - INFO - initializing Y\\n2024-01-04 14:28:21,645 - INFO - initializing inference method\\n2024-01-04 14:28:21,645 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:28:22,562 - INFO - '), ('4.0', '\\n2024-01-04 14:16:39,192 - INFO - This is check step: 3\\n2024-01-04 14:16:39,414 - INFO - Expansion of bounds dataframe at Iteration 4.0\\n2024-01-04 14:16:39,737 - INFO - initializing Y\\n2024-01-04 14:16:39,737 - INFO - initializing inference method\\n2024-01-04 14:16:39,737 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:16:40,642 - INFO - '), ('3.0', '\\n2024-01-04 14:15:47,978 - INFO - This is check step: 3\\n2024-01-04 14:15:48,190 - INFO - Expansion of bounds dataframe at Iteration 3.0\\n2024-01-04 14:15:48,493 - INFO - initializing Y\\n2024-01-04 14:15:48,493 - INFO - initializing inference method\\n2024-01-04 14:15:48,493 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:15:49,387 - INFO - '), ('2.0', '\\n2024-01-04 14:15:25,848 - INFO - This is check step: 3\\n2024-01-04 14:15:26,057 - INFO - Expansion of bounds dataframe at Iteration 2.0\\n2024-01-04 14:15:26,412 - INFO - initializing Y\\n2024-01-04 14:15:26,412 - INFO - initializing inference method\\n2024-01-04 14:15:26,412 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:15:27,298 - INFO - '), ('1.0', '\\n2024-01-04 14:14:22,441 - INFO - This is check step: 2\\n2024-01-04 14:14:23,032 - INFO - initializing Y\\n2024-01-04 14:14:23,032 - INFO - initializing inference method\\n2024-01-04 14:14:23,048 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:14:23,898 - INFO - '), ('0.0', '\\n2024-01-04 14:13:21,916 - INFO - This is check step: 2\\n2024-01-04 14:13:22,712 - INFO - initializing Y\\n2024-01-04 14:13:22,712 - INFO - initializing inference method\\n2024-01-04 14:13:22,712 - INFO - adding kernel and likelihood as parameters\\n2024-01-04 14:13:23,611 - INFO - ')]\n",
      "Last iteration with 'Expansion of bounds dataframe': 4\n"
     ]
    }
   ],
   "source": [
    "def it_count(start_exp_num, fin_exp_num, suggest_amount, project_name):\n",
    "    \"\"\"\n",
    "    Calculate iteration-related values based on the start and finish experiment numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - start_exp_num (int): Starting experiment number.\n",
    "    - fin_exp_num (int): Finish experiment number.\n",
    "    - suggest_amount (int): Number of experiments to suggest.\n",
    "    - PROJECT_NAME (str): Name of the project.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing iteration number, model names, and iteration names.\n",
    "    \"\"\"\n",
    "\n",
    "    if fin_exp_num < start_exp_num:\n",
    "        raise ValueError(\"Finish experiment number should be greater than or equal to the start experiment number.\")\n",
    "\n",
    "    current_it = (fin_exp_num - start_exp_num) / suggest_amount\n",
    "    next_it = current_it + 1\n",
    "    prev_it = current_it - 1\n",
    "    \n",
    "    model_name = f\"{project_name}_Model_It{current_it}.json\"\n",
    "    prev_model_name = f\"{project_name}_Model_It{prev_it}.json\"\n",
    "    it_name = f\"{project_name}_Exp_It{next_it}.csv\"\n",
    "    prev_it_name = f\"{project_name}_Exp_It{current_it}.csv\"\n",
    "\n",
    "    return current_it, model_name, prev_model_name, it_name, prev_it_name\n",
    "\n",
    "def find_last_iteration_with_log(log_file_path, log_message):\n",
    "    \"\"\"\n",
    "    Find the last iteration number with a specific log message in the log file.\n",
    "\n",
    "    Parameters:\n",
    "    - log_file_path (str): Path to the log file.\n",
    "    - log_message (str): Log message to search for.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[bool, int or None]: (True, iteration) if the log message is found, (False, None) otherwise.\n",
    "    \"\"\"\n",
    "    # Updated regex to capture iteration number with decimals\n",
    "    pattern = re.compile(r\"Iteration ([\\d.]+): Program started(.*?)Iteration \\1: Program completed\", re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as log_file:\n",
    "            log_content = log_file.read()\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: Log file '{log_file_path}' not found. Please check the file path.\")\n",
    "        return False, None\n",
    "\n",
    "    matches = re.findall(pattern, log_content)\n",
    "\n",
    "    # Reverse the order to start from the last iteration\n",
    "    matches.reverse()\n",
    "    print(matches)\n",
    "    for iteration, logs in matches[:3]:  # Look in the last 3 iterations\n",
    "        if log_message.lower() in logs.lower():  # Case-insensitive comparison\n",
    "            return True, int(float(iteration))\n",
    "\n",
    "    return False, None\n",
    "\n",
    "# Example usage\n",
    "log_message = \"Expansion of bounds dataframe\"\n",
    "check, last_iteration = find_last_iteration_with_log(log_file_path, log_message)\n",
    "\n",
    "if last_iteration is not None:\n",
    "    print(f\"Last iteration with '{log_message}': {last_iteration}\")\n",
    "else:\n",
    "    print(\"Log message not found or log file not accessible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9923dca-5873-463b-a3bd-2f4d5f44732d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_distance = 2\n",
    "EXPLORE_QUAN = 3\n",
    "\n",
    "def perform_summit_optimization(data_df, suggest_amount, expression, domain, project_name, model_path, it_path, start_exp_num, fin_exp_num, current_it, model_name, prev_model_name, it_name, prev_it_name):\n",
    "    \"\"\"\n",
    "    Perform Summit optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - data_df (pd.DataFrame): Data DataFrame.\n",
    "    - suggest_amount (int): Number of experiments to suggest.\n",
    "    - expression (str): Mathematical expression for optimization.\n",
    "    - domain (dict): Domain for optimization.\n",
    "    - project_name (str): Name of the project.\n",
    "    - model_path (Path): Path to save/load optimization model.\n",
    "    - it_path (Path): Path to save iteration data.\n",
    "    - start_exp_num (int): Starting experiment number.\n",
    "    - fin_exp_num (int): Finish experiment number.\n",
    "    \"\"\"\n",
    "\n",
    "    if check_distance = 0:\n",
    "        \n",
    "        transform = MultitoSingleObjective(\n",
    "            domain = domain,\n",
    "            expression = expression,\n",
    "            maximize = True\n",
    "        )\n",
    "        \n",
    "        strategy = SOBO(\n",
    "            domain = domain,\n",
    "            transform = transform\n",
    "        )\n",
    "\n",
    "        new_it = strategy.suggest_experiments(\n",
    "            num_experiments = suggest_amount,\n",
    "            prev_res = data_df\n",
    "        )\n",
    "        \n",
    "        it_exp_df = pd.concat([data_df, new_it], axis = 0)\n",
    "        it_exp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        # data_path = os.path.join(data_path, DATA_NAME)\n",
    "        # it_exp_df.to_csv(data_path, index=True)\n",
    "        \n",
    "        it_data_path = os.path.join(it_path, it_name)\n",
    "        new_it.to_csv(it_data_path)\n",
    "        \n",
    "        model_data_path = os.path.join(model_path, model_name)\n",
    "        strategy.save(model_data_path)\n",
    "        \n",
    "        print(\"Your first new experimental condition has been added to run. The model has been saved in the directory.\")\n",
    "        print(new_it)\n",
    "\n",
    "    if current_it == 0:\n",
    "\n",
    "        transform = MultitoSingleObjective(\n",
    "            domain = domain,\n",
    "            expression = expression,\n",
    "            maximize = True\n",
    "        )\n",
    "        \n",
    "        strategy = SOBO(\n",
    "            domain = domain,\n",
    "            transform = transform\n",
    "        )\n",
    "\n",
    "        new_it = strategy.suggest_experiments(\n",
    "            num_experiments = suggest_amount,\n",
    "            prev_res = data_df\n",
    "        )\n",
    "        \n",
    "        it_exp_df = pd.concat([data_df, new_it], axis = 0)\n",
    "        it_exp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        # data_path = os.path.join(data_path, DATA_NAME)\n",
    "        # it_exp_df.to_csv(data_path, index=True)\n",
    "        \n",
    "        it_data_path = os.path.join(it_path, it_name)\n",
    "        new_it.to_csv(it_data_path)\n",
    "        \n",
    "        model_data_path = os.path.join(model_path, model_name)\n",
    "        strategy.save(model_data_path)\n",
    "        \n",
    "        print(\"Your first new experimental condition has been added to run. The model has been saved in the directory.\")\n",
    "        print(new_it)\n",
    "\n",
    "    else: \n",
    "\n",
    "        prev_it = data_df.iloc[-1:].copy()\n",
    "        prev_it.to_csv(it_path / prev_it_name)\n",
    "        strategy = SOBO.load(model_path / prev_model_name)\n",
    "        \n",
    "        new_it = strategy.suggest_experiments(\n",
    "            num_experiments = suggest_amount,\n",
    "            prev_res = prev_it\n",
    "        )\n",
    "        \n",
    "        it_exp_df = pd.concat([data_df, new_it], axis = 0)\n",
    "        it_exp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        # data_path = os.path.join(data_path, DATA_NAME)\n",
    "        # it_exp_df.to_csv(data_path, index=True)\n",
    "        \n",
    "        it_data_path = os.path.join(it_path, it_name)\n",
    "        new_it.to_csv(it_data_path)\n",
    "        \n",
    "        model_data_path = os.path.join(model_path, model_name)\n",
    "        strategy.save(model_data_path)\n",
    "        \n",
    "        print(\"A new experimental condition has been added to run. The model has been saved in the directory.\")\n",
    "        print(new_it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d34553-7bf1-4992-ac2f-9627d1d99c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
