{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6c7f07-3cfb-4659-8165-0ffea65fbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing all needed libraries\n",
    "try:\n",
    "    # Summit-related imports\n",
    "    import summit\n",
    "    from summit.benchmarks import ExperimentalEmulator\n",
    "    from summit.domain import *\n",
    "    from summit.utils.dataset import DataSet\n",
    "    from summit.strategies import SOBO, MultitoSingleObjective, LHS\n",
    "\n",
    "    # External libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # File and path handling\n",
    "    import pathlib\n",
    "    import os\n",
    "    import logging\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error: {e}. Please install the required libraries before running the program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63762296-4c9a-495e-91f4-c99abcec7de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurable parameters\n",
    "base_path = pathlib.Path(\"D:/!PythonCode/ChemistryOptimization/DataSets/MidazTest\")\n",
    "PROJECT_NAME = \"MidazTest\"\n",
    "BOUNDS_NAME = f\"{PROJECT_NAME}_Bounds.csv\"\n",
    "DATA_NAME = f\"{PROJECT_NAME}_Data.csv\"\n",
    "LOG_NAME = f\"{PROJECT_NAME}_Log.csv\"\n",
    "#BOUNDS_NAME = \"Nakul_Midazolam_BoundariesV2.csv\"\n",
    "#DATA_NAME = \"StartExp.csv\"\n",
    "\n",
    "# Folder Name\n",
    "DATA_DIR = \"Data\"\n",
    "MODEL_DIR = \"Models\"\n",
    "IT_DIR = \"IterData\"\n",
    "LOG_DIR = \"Logs\"\n",
    "\n",
    "# Function to create directory if it doesn't exist\n",
    "def create_directory(base_path, directory):\n",
    "    \"\"\"Create a directory if it doesn't exist.\"\"\"\n",
    "    dir_path = base_path / directory\n",
    "    if not dir_path.is_dir():\n",
    "        dir_path.mkdir(parents=True)\n",
    "        \n",
    "# Create directories\n",
    "for directory in [DATA_DIR, MODEL_DIR, IT_DIR, LOG_DIR]:\n",
    "    create_directory(base_path, directory)\n",
    "\n",
    "# Set data paths\n",
    "data_path = base_path / DATA_DIR\n",
    "model_path = base_path / MODEL_DIR\n",
    "it_path = base_path / IT_DIR\n",
    "log_path = base_path / LOG_DIR\n",
    "\n",
    "# Configure logging\n",
    "log_file_path = log_path / LOG_NAME\n",
    "logging.basicConfig(\n",
    "    filename = log_file_path,\n",
    "    level = logging.INFO,\n",
    "    format = \"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Load initial boundaries data\n",
    "try:\n",
    "    init_bounds_df = pd.read_csv(data_path / BOUNDS_NAME)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{BOUNDS_NAME}' not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: File '{BOUNDS_NAME}' is empty or in an invalid format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6cc257-ec22-4631-b0de-2ad164c7e848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_domain(init_bounds_df):\n",
    "    \"\"\"\n",
    "    Create a Summit domain based on the provided boundaries DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - init_bounds_df (pd.DataFrame): DataFrame containing information about variable boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - domain (Domain): The created Summit domain.\n",
    "    - obj_df (pd.DataFrame): DataFrame for objective variables.\n",
    "    - in_count (int): Count of input variables.\n",
    "    - out_count (int): Count of output variables.\n",
    "    \"\"\"\n",
    "    if not isinstance(init_bounds_df, pd.DataFrame) or init_bounds_df.empty:\n",
    "        raise ValueError(\"Invalid input: init_bounds_df must be a non-empty DataFrame.\")\n",
    "        \n",
    "    domain = Domain()\n",
    "    obj_df = pd.DataFrame()\n",
    "    obj_df = DataSet.from_df(obj_df)\n",
    "\n",
    "    in_count = 0\n",
    "    out_count = 0\n",
    "\n",
    "    for idx, row in init_bounds_df.iterrows():\n",
    "        name = row[0]\n",
    "        description = row[5]\n",
    "        data_type = row[1]\n",
    "\n",
    "        if data_type == 'Categorical':\n",
    "            levels = row[2].split(',')\n",
    "\n",
    "            domain += CategoricalVariable(\n",
    "                name = name,\n",
    "                description = description,\n",
    "                levels = levels\n",
    "            )\n",
    "            in_count += 1\n",
    "\n",
    "        elif data_type == 'Continuous':\n",
    "            bounds = [row[3], row[4]]\n",
    "\n",
    "            domain += ContinuousVariable(\n",
    "                name = name,\n",
    "                description = description,\n",
    "                bounds = bounds\n",
    "            )\n",
    "            in_count += 1\n",
    "\n",
    "        elif data_type == 'Objective':\n",
    "            bounds = [row[3], row[4]]\n",
    "            maximize = row[6]\n",
    "\n",
    "            domain += ContinuousVariable(\n",
    "                name = name,\n",
    "                description = description,\n",
    "                bounds = bounds,\n",
    "                is_objective = True,\n",
    "                maximize = maximize\n",
    "            )\n",
    "            out_count += 1\n",
    "\n",
    "            obj_df[(name, \"DATA\")] = \"\"\n",
    "        \n",
    "    return domain, obj_df, in_count, out_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024c281f-7e24-4d1b-9562-d8fad0e71c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data_df, init_bounds_df, out_count):\n",
    "    \"\"\"\n",
    "    Preprocess the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - data_df (pd.DataFrame): Input data DataFrame.\n",
    "    - init_bounds_df (pd.DataFrame): DataFrame containing information about variable boundaries.\n",
    "    - out_count (int): Count of output variables.\n",
    "\n",
    "    Returns:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "    - in_bounds_thresh_df (pd.DataFrame): Thresholds for initial boundary data.\n",
    "    - INIT_BOUNDS_THRESH_FRAC (float): Fraction used for calculating bounds thresholds.\n",
    "    - ach_func_bounds (list): Achievement function bounds.\n",
    "    - ach_func_thresh (float): Threshold for the achievement function.\n",
    "    \"\"\"   \n",
    "    # Constants\n",
    "    DATA_COL_NAME = ('Achievement_Function','DATA')\n",
    "    BOUNDS_COL_NAME = 'Threshold'\n",
    "    INIT_BOUNDS_THRESH_FRAC = 0.10\n",
    "    ACH_FUNC_THRESH_FRAC = 0.025\n",
    "    \n",
    "    # Achievement function bounds\n",
    "    ach_func_bounds = [-1,1] #Change this to automatic later on    \n",
    "    \n",
    "    # Calculate the achievement function\n",
    "    data_df[DATA_COL_NAME] = data_df.iloc[:, -2] - data_df.iloc[:, -1]\n",
    "    \n",
    "    # Copy the data DataFrame and sorts by the achievement function\n",
    "    sorted_data_df = data_df.sort_values(\n",
    "        by = DATA_COL_NAME,\n",
    "        ascending = False\n",
    "    ).copy()\n",
    "\n",
    "    # Create a copy of the initial bounds DataFrame\n",
    "    bounds_thresh_df = init_bounds_df.copy()\n",
    "    \n",
    "    # Calculate the threshold for the initial boundaries\n",
    "    bounds_thresh_df[BOUNDS_COL_NAME] = (init_bounds_df.iloc[:, 4] - init_bounds_df.iloc[:, 3])*INIT_BOUNDS_THRESH_FRAC\n",
    "\n",
    "    # Create a copy of the initial boundaries + threshold DataFrame and removes the output boundaries + threshold\n",
    "    in_bounds_thresh_df = bounds_thresh_df.iloc[:-(out_count)].copy()\n",
    "\n",
    "    # Calculate the achievement function threshold\n",
    "    ach_func_thresh = (ach_func_bounds[1] - ach_func_bounds[0])*ACH_FUNC_THRESH_FRAC\n",
    "    \n",
    "    return sorted_data_df, in_bounds_thresh_df, INIT_BOUNDS_THRESH_FRAC, ach_func_bounds, ach_func_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8bdd1a-fbf7-48f9-90c1-67b47145dc07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##All check functions\n",
    "def check_af_converg(sorted_data_df):\n",
    "    \"\"\"\n",
    "    Check the convergence of the achievement function for the top 3 rows.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - avg_diff_top_3 (float): Average absolute difference of the achievement function for the top 3 rows from their mean.\n",
    "    \"\"\"\n",
    "    if len(sorted_data_df) < 3:\n",
    "        raise ValueError(\"Insufficient data for convergence check. Need at least 3 rows.\")\n",
    "\n",
    "    top_3_af = sorted_data_df.iloc[:3, -1]\n",
    "    avg_top_3 = top_3_af.mean()\n",
    "    avg_diff_top_3 = np.abs(top_3_af - avg_top_3).mean()\n",
    "\n",
    "    return avg_diff_top_3\n",
    "    \n",
    "def check_bounds(sorted_data_df, in_bounds_thresh_df, out_count):\n",
    "    \"\"\"\n",
    "    Check if conditions are close to the upper or lower bounds.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "    - in_bounds_thresh_df (pd.DataFrame): Thresholds for initial boundary data.\n",
    "    - out_count (int): Count of output variables.\n",
    "\n",
    "    Returns:\n",
    "    - close_to_max_bounds (list): Conditions close to the upper bounds.\n",
    "    - close_to_min_bounds (list): Conditions close to the lower bounds.\n",
    "    \"\"\"\n",
    "    if sorted_data_df.empty or in_bounds_thresh_df.empty:\n",
    "        raise ValueError(\"Input DataFrames cannot be empty.\")\n",
    "    \n",
    "    close_to_max_bounds = []\n",
    "    close_to_min_bounds = []\n",
    "    check_exp = sorted_data_df.iloc[0, 0:-(out_count + 2)].to_numpy()\n",
    "    \n",
    "    for idx, row in in_bounds_thresh_df.iterrows():\n",
    "        col_name = row['Condition']\n",
    "        min_bounds = row['BoundaryMin']\n",
    "        max_bounds = row['BoundaryMax']\n",
    "        thresh = row['Threshold']\n",
    "        val = check_exp[idx]\n",
    "        \n",
    "        if np.isfinite(val):\n",
    "            if (val - min_bounds) < thresh:\n",
    "                close_to_min_bounds.append(col_name)\n",
    "            elif (max_bounds - val) < thresh:\n",
    "                close_to_max_bounds.append(col_name)\n",
    "                \n",
    "    return close_to_max_bounds, close_to_min_bounds\n",
    "\n",
    "def check_max_possibility(sorted_data_df, ach_func_thresh, ach_func_bounds):\n",
    "    \"\"\"\n",
    "    Check if the achievement function is close to the upper bound.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "    - ach_func_thresh (float): Threshold for the achievement function.\n",
    "    - ach_func_bounds (list): Achievement function bounds.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if near the upper bound, False otherwise.\n",
    "    \"\"\"\n",
    "    if sorted_data_df.empty:\n",
    "        raise ValueError(\"Input DataFrame 'sorted_data_df' cannot be empty.\")\n",
    "    \n",
    "    if not ach_func_bounds or len(ach_func_bounds) != 2:\n",
    "        raise ValueError(\"Invalid 'ach_func_bounds'. It should be a list of two values representing bounds.\")\n",
    "    \n",
    "    if ach_func_thresh is None or not isinstance(ach_func_thresh, (int, float)):\n",
    "        raise ValueError(\"Invalid 'ach_func_thresh'. It should be a numeric value.\")\n",
    "    \n",
    "    upper_bound = ach_func_bounds[1]\n",
    "    achievement_function_value = sorted_data_df.iloc[0, -1]\n",
    "\n",
    "    if abs(achievement_function_value - upper_bound) < ach_func_thresh:\n",
    "        print('Near the maximum possibility. Optimization has ended.')\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def check_goal(sorted_data_df, GOAL):\n",
    "    \"\"\"\n",
    "    Check if the optimized result exceeds the specified goal.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "    - GOAL (float): Target goal.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the goal is achieved, False otherwise.\n",
    "    \"\"\"\n",
    "    if sorted_data_df.empty:\n",
    "        raise ValueError(\"Input DataFrame 'sorted_data_df' cannot be empty.\")\n",
    "\n",
    "    if GOAL is None or not isinstance(GOAL, (int, float)):\n",
    "        raise ValueError(\"Invalid 'GOAL'. It should be a numeric value.\")\n",
    "\n",
    "    # Check if the goal is achieved\n",
    "    if sorted_data_df.iloc[0, -1] > GOAL:\n",
    "        print('Optimized to the goal within given boundaries')\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def expand_bounds(sorted_data_df, in_bounds_thresh_df, init_bounds_df, EXPANSION_COEF, INIT_BOUNDS_THRESH_FRAC, out_count):\n",
    "    \"\"\"\n",
    "    Expand boundaries based on parameters near the bounds.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_data_df (pd.DataFrame): Sorted data DataFrame.\n",
    "    - in_bounds_thresh_df (pd.DataFrame): Thresholds for initial boundary data.\n",
    "    - init_bounds_df (pd.DataFrame): Initial boundaries DataFrame.\n",
    "    - EXPANSION_COEF (float): Expansion coefficient.\n",
    "    - INIT_BOUNDS_THRESH_FRAC (float): Fraction used for calculating bounds thresholds.\n",
    "    - out_count (int): Count of output variables.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if no parameters near the boundaries, False otherwise.\n",
    "    \"\"\"\n",
    "    if sorted_data_df.empty or in_bounds_thresh_df.empty or init_bounds_df.empty:\n",
    "        raise ValueError(\"Input DataFrames cannot be empty.\")\n",
    "        \n",
    "    # Check if there are parameters near the bounds\n",
    "    close_to_max_bounds, close_to_min_bounds = check_bounds(sorted_data_df, in_bounds_thresh_df, out_count)\n",
    "    \n",
    "    if not (close_to_max_bounds or close_to_min_bounds):\n",
    "        print('No parameters near the boundaries')\n",
    "        return True\n",
    "\n",
    "   # Expand the boundaries based on proximity to the bounds\n",
    "    for parameter in close_to_max_bounds:\n",
    "        param_bounds_row = init_bounds_df.loc[init_bounds_df.iloc[:, 0] == parameter].copy()\n",
    "        param_bounds_row.iloc[:, 4] += EXPANSION_COEF * (param_bounds_row.iloc[:, 4] - param_bounds_row.iloc[:, 3])\n",
    "        init_bounds_df.loc[init_bounds_df.iloc[:, 0] == parameter] = param_bounds_row\n",
    "\n",
    "    for parameter in close_to_min_bounds:\n",
    "        param_bounds_row = init_bounds_df.loc[init_bounds_df.iloc[:, 0] == parameter].copy()\n",
    "        param_bounds_row.iloc[:, 3] -= EXPANSION_COEF * (param_bounds_row.iloc[:, 4] - param_bounds_row.iloc[:, 3])\n",
    "        init_bounds_df.loc[init_bounds_df.iloc[:, 0] == parameter] = param_bounds_row\n",
    "\n",
    "    return False\n",
    "\n",
    "def find_last_iteration_with_log(log_file_path, log_message):\n",
    "    \"\"\"\n",
    "    Find the last iteration number with a specific log message in the log file.\n",
    "\n",
    "    Parameters:\n",
    "    - log_file_path (str): Path to the log file.\n",
    "    - log_message (str): Log message to search for.\n",
    "\n",
    "    Returns:\n",
    "    - int or None: Last iteration number with the log message, or None if not found.\n",
    "    \"\"\"\n",
    "    # Updated regex to capture iteration number with decimals\n",
    "    pattern = re.compile(r\"Iteration ([\\d.]+): Program started(.*?)Iteration \\1: Program completed\", re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as log_file:\n",
    "            log_content = log_file.read()\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: Log file '{log_file_path}' not found. Please check the file path.\")\n",
    "        return False, None\n",
    "\n",
    "    matches = re.findall(pattern, log_content)\n",
    "\n",
    "    # Reverse the order to start from the last iteration\n",
    "    matches.reverse()\n",
    "\n",
    "    for iteration, logs in matches[:3]:  # Look in the last 3 iterations\n",
    "        if log_message.lower() in logs.lower():  # Case-insensitive comparison\n",
    "            return True, int(float(iteration))\n",
    "\n",
    "    return False, None\n",
    "\n",
    "def check_steps(init_bounds_df, GOAL, EXPANSION_COEF, data_df, out_count, verbose=False):\n",
    "    \"\"\"\n",
    "    Check the optimization stage based on the current state of the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - init_bounds_df (pd.DataFrame): Initial boundaries DataFrame.\n",
    "    - GOAL (float): Target goal.\n",
    "    - EXPANSION_COEF (float): Expansion coefficient.\n",
    "    - data_df (pd.DataFrame): Input data DataFrame.\n",
    "    - out_count (int): Count of output variables.\n",
    "    - verbose (bool): Whether to print detailed information.\n",
    "\n",
    "    Returns:\n",
    "    - int: Check step (1, 2, 3, 4, or 5).\n",
    "    \"\"\"\n",
    "\n",
    "    log_message = \"Expansion of bounds dataframe\"\n",
    "    sorted_data_df, in_bounds_thresh_df, INIT_BOUNDS_THRESH_FRAC, ach_func_bounds, ach_func_thresh = preprocess_data(data_df, init_bounds_df, out_count)\n",
    "\n",
    "    if check_max_possibility(sorted_data_df, ach_func_thresh, ach_func_bounds):\n",
    "        if verbose:\n",
    "            print('Near the maximum possibility. Optimization has ended.')\n",
    "        return CHECK_STEP_OPTIMIZATION_ENDS\n",
    "\n",
    "    log_found, last_iteration = find_last_iteration_with_log(log_file_path, log_message)\n",
    "\n",
    "    if log_found:\n",
    "        if verbose:\n",
    "            print(f\"Log message '{log_message}' found in iteration {last_iteration}.\")\n",
    "        return CHECK_STEP_LOG_MESSAGE_FOUND\n",
    "\n",
    "    elif check_af_converg(sorted_data_df) < (ach_func_thresh / 2):\n",
    "        if check_goal(sorted_data_df, GOAL):\n",
    "            if verbose:\n",
    "                print('Optimized to the goal within given boundaries.')\n",
    "            return CHECK_STEP_OPTIMIZATION_ENDS\n",
    "\n",
    "        elif not expand_bounds(sorted_data_df, in_bounds_thresh_df, init_bounds_df, EXPANSION_COEF, INIT_BOUNDS_THRESH_FRAC, out_count):\n",
    "            if verbose:\n",
    "                print('The boundaries have been expanded. Please continue optimization.')\n",
    "            return CHECK_STEP_EXPAND_BOUNDS\n",
    "\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Optimized under the set goal. The reaction conditions have hit a plateau. Reevaluate the data.')\n",
    "            return CHECK_STEP_HIT_PLATEAU\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Continue with the optimization process.')\n",
    "        return CHECK_STEP_CONTINUE_OPTIMIZATION\n",
    "\n",
    "# Constants for check steps\n",
    "CHECK_STEP_OPTIMIZATION_ENDS = 1\n",
    "CHECK_STEP_CONTINUE_OPTIMIZATION = 2\n",
    "CHECK_STEP_EXPAND_BOUNDS = 3\n",
    "CHECK_STEP_HIT_PLATEAU = 4\n",
    "CHECK_STEP_LOG_MESSAGE_FOUND = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afafbb05-981e-4daa-adfa-3e7c46438d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def it_count(start_exp_num, fin_exp_num, suggest_amount, project_name):\n",
    "    \"\"\"\n",
    "    Calculate iteration-related values based on the start and finish experiment numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - start_exp_num (int): Starting experiment number.\n",
    "    - fin_exp_num (int): Finish experiment number.\n",
    "    - suggest_amount (int): Number of experiments to suggest.\n",
    "    - PROJECT_NAME (str): Name of the project.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing iteration number, model names, and iteration names.\n",
    "    \"\"\"\n",
    "\n",
    "    if fin_exp_num < start_exp_num:\n",
    "        raise ValueError(\"Finish experiment number should be greater than or equal to the start experiment number.\")\n",
    "\n",
    "    current_it = (fin_exp_num - start_exp_num) / suggest_amount\n",
    "    next_it = current_it + 1\n",
    "    prev_it = current_it - 1\n",
    "    \n",
    "    model_name = f\"{project_name}_Model_It{current_it}.json\"\n",
    "    prev_model_name = f\"{project_name}_Model_It{prev_it}.json\"\n",
    "    it_name = f\"{project_name}_Exp_It{next_it}.csv\"\n",
    "    prev_it_name = f\"{project_name}_Exp_It{current_it}.csv\"\n",
    "\n",
    "    return current_it, model_name, prev_model_name, it_name, prev_it_name\n",
    "\n",
    "\n",
    "def create_initial_dataset(domain, DATA_NAME, START_EXP_NUM, RANDOM_SEED = 808): \n",
    "    \"\"\"\n",
    "    Create the initial dataset file and DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - domain (dict): Domain for Latin Hypercube Sampling.\n",
    "    - DATA_NAME (str): Name of the dataset file.\n",
    "    - START_EXP_NUM (int): Starting experiment number.\n",
    "    - RANDOM_SEED (int): Seed for random number generation.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Initial experiment DataFrame.\n",
    "    \"\"\"\n",
    "    categorical_method = \"one-hot\"\n",
    "    \n",
    "    initial_strategy = LHS(\n",
    "        domain = domain, \n",
    "        random_state = np.random.RandomState(random_seed),\n",
    "        categorical_method = categorical_method\n",
    "    ) \n",
    "    \n",
    "    temp_start_exp_df = pd.DataFrame(initial_strategy.suggest_experiments(START_EXP_NUM)) \n",
    "    start_exp = pd.concat(\n",
    "        [temp_start_exp_df, obj_df],\n",
    "        axis = 1\n",
    "    ) \n",
    "    \n",
    "    # Check if the file already exists before overwriting\n",
    "    file_path = data_path / data_name\n",
    "    if file_path.exists():\n",
    "        overwrite = input(f\"The file '{data_name}' already exists. Do you want to overwrite it? (y/n): \")\n",
    "        if overwrite.lower() != 'y':\n",
    "            print(\"Operation canceled.\")\n",
    "            return start_exp\n",
    "        \n",
    "    start_exp.to_csv(\n",
    "        data_path / DATA_NAME,\n",
    "        index = True\n",
    "    ) \n",
    "        \n",
    "    print(f\"The file '{DATA_NAME}' does not exist in the directory. A new file has been created, please update it with results\") \n",
    "    return start_exp\n",
    "\n",
    "#Function to do Summit optimization\n",
    "def perform_summit_optimization(data_df, suggest_amount, expression, domain, project_name, model_path, it_path, start_exp_num, fin_exp_num, current_it, model_name, prev_model_name, it_name, prev_it_name):\n",
    "    \"\"\"\n",
    "    Perform Summit optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - data_df (pd.DataFrame): Data DataFrame.\n",
    "    - suggest_amount (int): Number of experiments to suggest.\n",
    "    - expression (str): Mathematical expression for optimization.\n",
    "    - domain (dict): Domain for optimization.\n",
    "    - project_name (str): Name of the project.\n",
    "    - model_path (Path): Path to save/load optimization model.\n",
    "    - it_path (Path): Path to save iteration data.\n",
    "    - start_exp_num (int): Starting experiment number.\n",
    "    - fin_exp_num (int): Finish experiment number.\n",
    "    \"\"\"\n",
    "\n",
    "    if current_it == 0:\n",
    "\n",
    "        transform = MultitoSingleObjective(\n",
    "            domain = domain,\n",
    "            expression = expression,\n",
    "            maximize = True\n",
    "        )\n",
    "        \n",
    "        strategy = SOBO(\n",
    "            domain = domain,\n",
    "            transform = transform\n",
    "        )\n",
    "\n",
    "        new_it = strategy.suggest_experiments(\n",
    "            num_experiments = suggest_amount,\n",
    "            prev_res = data_df\n",
    "        )\n",
    "        \n",
    "        it_exp_df = pd.concat([data_df, new_it], axis = 0)\n",
    "        it_exp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        # data_path = os.path.join(data_path, DATA_NAME)\n",
    "        # it_exp_df.to_csv(data_path, index=True)\n",
    "        \n",
    "        it_data_path = os.path.join(it_path, it_name)\n",
    "        new_it.to_csv(it_data_path)\n",
    "        \n",
    "        model_data_path = os.path.join(model_path, model_name)\n",
    "        strategy.save(model_data_path)\n",
    "        \n",
    "        print(\"Your first new experimental condition has been added to run. The model has been saved in the directory.\")\n",
    "        print(new_it)\n",
    "\n",
    "    else: \n",
    "\n",
    "        prev_it = data_df.iloc[-1:].copy()\n",
    "        prev_it.to_csv(it_path / prev_it_name)\n",
    "        strategy = SOBO.load(model_path / prev_model_name)\n",
    "        \n",
    "        new_it = strategy.suggest_experiments(\n",
    "            num_experiments = suggest_amount,\n",
    "            prev_res = prev_it\n",
    "        )\n",
    "        \n",
    "        it_exp_df = pd.concat([data_df, new_it], axis = 0)\n",
    "        it_exp_df.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        # data_path = os.path.join(data_path, DATA_NAME)\n",
    "        # it_exp_df.to_csv(data_path, index=True)\n",
    "        \n",
    "        it_data_path = os.path.join(it_path, it_name)\n",
    "        new_it.to_csv(it_data_path)\n",
    "        \n",
    "        model_data_path = os.path.join(model_path, model_name)\n",
    "        strategy.save(model_data_path)\n",
    "        \n",
    "        print(\"A new experimental condition has been added to run. The model has been saved in the directory.\")\n",
    "        print(new_it)\n",
    "\n",
    "def create_progress_graph(data_df, start_exp_num):\n",
    "    \"\"\"\n",
    "    Create a progress graph to visualize the achievement function over experiment numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - data_df (pd.DataFrame): Data DataFrame.\n",
    "    - start_exp_num (int): Starting experiment number.\n",
    "    \"\"\"\n",
    "    data_exp_num = data_df.index + 1\n",
    "    data_ach_func = pd.to_numeric(data_df.iloc[:, -1], errors='coerce')  # Convert to numeric, handle errors as NaN\n",
    "\n",
    "    # Split the data into two parts for better visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(\n",
    "        data_exp_num[:start_exp_num],\n",
    "        data_ach_func[:start_exp_num],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='grey',\n",
    "        markersize=5,\n",
    "        linewidth=1,\n",
    "        label='Best Achievement (Initial)'\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        data_exp_num[start_exp_num:],\n",
    "        data_ach_func[start_exp_num:],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='navy',\n",
    "        markersize=5,\n",
    "        linewidth=1,\n",
    "        label='Best Achievement (After Optimization)'\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Experiment Number')\n",
    "    plt.ylabel('Achievement Function')\n",
    "    plt.title('Experiment Results')\n",
    "    plt.legend()  # Add legend to differentiate initial and optimized achievements\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c406a6d-e0b5-4efd-a0a7-a61db83a00ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Runs the main code of the algorithm \u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_it\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Program started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Check the status of the optimization progress\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m check_step \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_bounds_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGOAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEXPANSION_COEF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is check step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Creates the progress graph\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 205\u001b[0m, in \u001b[0;36mcheck_steps\u001b[1;34m(init_bounds_df, GOAL, EXPANSION_COEF, data_df, out_count, verbose)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNear the maximum possibility. Optimization has ended.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CHECK_STEP_OPTIMIZATION_ENDS\n\u001b[1;32m--> 205\u001b[0m log_found, last_iteration \u001b[38;5;241m=\u001b[39m \u001b[43mfind_last_iteration_with_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_found:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[1;32mIn[11], line 161\u001b[0m, in \u001b[0;36mfind_last_iteration_with_log\u001b[1;34m(log_file_path, log_message)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03mFind the last iteration number with a specific log message in the log file.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m- int or None: Last iteration number with the log message, or None if not found.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Updated regex to capture iteration number with decimals\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration ([\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md.]+): Program started(.*?)Iteration \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1: Program completed\u001b[39m\u001b[38;5;124m\"\u001b[39m, re\u001b[38;5;241m.\u001b[39mDOTALL \u001b[38;5;241m|\u001b[39m re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m log_file:\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Constants\n",
    "    file_path = os.path.join(data_path, DATA_NAME)\n",
    "    START_EXP_NUM = 10\n",
    "    SUGGEST_AMOUNT = 1\n",
    "    EXPRESSION = \"Main_Product-Main_Impurity\"\n",
    "    GOAL = 0.8\n",
    "    EXPANSION_COEF = 1\n",
    "    \n",
    "    domain, obj_df, in_count, out_count = create_domain(init_bounds_df)\n",
    "    \n",
    "    # Determines if there is an initial dataset that exists\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.info(f\"Creating initial dataset: {DATA_NAME}\")\n",
    "        create_initial_dataset(domain, DATA_NAME, START_EXP_NUM)\n",
    "        return\n",
    "    \n",
    "    # Reads the initial dataset\n",
    "    data_df = DataSet.read_csv(data_path / DATA_NAME) \n",
    "    logging.info(f\"Reading dataset: {DATA_NAME}\")\n",
    "    \n",
    "    # Determines that amount of total experiments equal amount of completed experiments\n",
    "    exp_num = data_df.iloc[:, 0].count()\n",
    "    fin_exp_num = data_df.iloc[:, -1].count()\n",
    "    if exp_num - fin_exp_num != 0:\n",
    "        logging.warning(\"Complete experiments and update .csv file.\")\n",
    "        return\n",
    "    \n",
    "    # Calculates the current iteration as well as all the names of models and iterations needed\n",
    "    current_it, model_name, prev_model_name, it_name, prev_it_name = it_count(START_EXP_NUM, fin_exp_num, SUGGEST_AMOUNT, PROJECT_NAME)\n",
    "    logging.info(f\"Iteration {current_it}: Program started\")\n",
    "    \n",
    "    # Check the status of the optimization progress\n",
    "    check_step = check_steps(init_bounds_df, GOAL, EXPANSION_COEF, data_df, out_count)\n",
    "    logging.info(f\"This is check step: {check_step}\")\n",
    "    \n",
    "    # Creates the progress graph\n",
    "    create_progress_graph(data_df, START_EXP_NUM)\n",
    "\n",
    "    # Reports what the status of the optimization progress is and halts the program or continues\n",
    "    if check_step == 1 or check_step == 4:\n",
    "        logging.warning(\"Optimization has been halted\")\n",
    "        return\n",
    "\n",
    "    if check_step == 3:\n",
    "        logging.info(f\"Expansion of bounds dataframe\")\n",
    "        domain = create_domain(init_bounds_df)\n",
    "        \n",
    "    # Performs the primiary optimization \n",
    "    perform_summit_optimization(data_df, SUGGEST_AMOUNT, EXPRESSION, domain, PROJECT_NAME, model_path, it_path, START_EXP_NUM, fin_exp_num, current_it, model_name, prev_model_name, it_name, prev_it_name)\n",
    "    \n",
    "    # Log the iteration number at the end of the program\n",
    "    logging.info(f\"Iteration {current_it}: Program completed\")\n",
    "\n",
    "\n",
    "# Runs the main code of the algorithm \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f85c19-eb1b-4eea-b87a-29b599df98fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
